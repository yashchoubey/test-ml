{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7762,
     "status": "ok",
     "timestamp": 1528710397884,
     "user": {
      "displayName": "Yash Choubey",
      "photoUrl": "//lh5.googleusercontent.com/-UBdihS33LU4/AAAAAAAAAAI/AAAAAAAAEIA/Xb_W4xj5Wys/s50-c-k-no/photo.jpg",
      "userId": "116223453474966761812"
     },
     "user_tz": -330
    },
    "id": "ogmC919pA5oS",
    "outputId": "3b082ee8-b079-4786-ad3c-40d1e4faaa5c"
   },
   "outputs": [],
   "source": [
    "# !wget http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
    "# !wget https://s3.ap-south-1.amazonaws.com/discovery-nlp-data/dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1528710475112,
     "user": {
      "displayName": "Yash Choubey",
      "photoUrl": "//lh5.googleusercontent.com/-UBdihS33LU4/AAAAAAAAAAI/AAAAAAAAEIA/Xb_W4xj5Wys/s50-c-k-no/photo.jpg",
      "userId": "116223453474966761812"
     },
     "user_tz": -330
    },
    "id": "U54yg4lCg4Mv",
    "outputId": "e75a93a6-5762-4fc0-873a-fa9e83635b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence   type\n",
      "0  MUCH better than the West Hollywood property w...  Hotel\n",
      "1      Stay away from room service in my opinion....  Hotel\n",
      "2                           Room service was superb.  Hotel\n",
      "3  Stayed in a king suite for 11 nights and yes i...  Hotel\n",
      "4  The location close to the 72nd Street subway s...  Hotel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "df = pd.read_csv('/home/yash/Downloads/dataset.csv',sep=\",\",header=None ,names=['sentence','type'])\n",
    "\n",
    "print df.head()\n",
    "# df.apply(str)\n",
    "# type(df['sentence'][0])\n",
    "# embedding_matrix=np.load(\"my_matrix.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NCQmVq5DVOyF"
   },
   "outputs": [],
   "source": [
    "Y = df['type']\n",
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "Y=le.transform(Y) \n",
    "labels = to_categorical(np.asarray(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from unidecode import unidecode\n",
    "# fit_on_texts(textdata))\n",
    "MAX_NB_WORDS = 16384\n",
    "MAX_SEQUENCE_LENGTH=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "u-1gdoCzVbO7"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, split=' ')\n",
    "\n",
    "alist=[str(x) for x in df['sentence'].values ]\n",
    "tokenizer.fit_on_texts(alist)\n",
    "X=tokenizer.texts_to_sequences(alist)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "V0nmi0-fVqsm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917494 word vectors.\n",
      "Found 3650 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open('/home/yash/glove.42B.300d.txt')\n",
    "for line in f:\n",
    "    #print line\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "emb_dimension=300\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, emb_dimension))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.save(, embedding_matrix)\n",
    "embedding_matrix.dump('embd.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vS9gFiv-U300"
   },
   "outputs": [],
   "source": [
    "# from keras.layers import Embedding\n",
    "# word_index_len=20465\n",
    "# emb_dimension=300\n",
    "# embedding_layer = Embedding(word_index_len,\n",
    "#                             emb_dimension,\n",
    "#                             weights=[embedding_matrix],\n",
    "#                             input_length=MAX_SEQUENCE_LENGTH,\n",
    "#                             trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s9wDyWOcU34Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 128, 300)          1095300   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,863,304\n",
      "Trainable params: 768,004\n",
      "Non-trainable params: 1,095,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.callbacks import History ,ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "history = History()\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False))\n",
    "# model.add(embedding_layer)\n",
    "\n",
    "model.add(LSTM(256,\n",
    "               return_sequences=True, \n",
    "               dropout=0.4, \n",
    "               recurrent_dropout=0.4, \n",
    "               activation='relu',\n",
    "               kernel_regularizer=regularizers.l2(0.001)))#,activity_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "model.add(LSTM(128, \n",
    "               dropout=0.4, \n",
    "               recurrent_dropout=0.4, \n",
    "               activation='relu',\n",
    "               kernel_regularizer=regularizers.l2(0.001)))#,activity_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "#model.add(LSTM(256, dropout_U=0.5, dropout_W=0.5, activation='relu', kernel_regularizer=l2_reg))\n",
    "model.add(Dense(4,activation='softmax'))#,kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01)))\n",
    "rmsprop = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=rmsprop,metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OeDFyM04U38q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1575 samples, validate on 394 samples\n",
      "Epoch 1/2\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 2.1614 - acc: 0.3778 - val_loss: 1.6609 - val_acc: 0.5431\n",
      "Epoch 2/2\n",
      "1575/1575 [==============================] - 3s 2ms/step - loss: 1.5773 - acc: 0.5276 - val_loss: 1.6266 - val_acc: 0.5660\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5, min_lr=0.0001, cooldown=5)\n",
    "history=model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          callbacks=[reduce_lr],\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q8_yS5rUU4AI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6241612  0.17492281 0.08832416 0.11259187]] <type 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FB'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = tokenizer.texts_to_sequences([\"food was worse\"])\n",
    "example = pad_sequences(example, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print model.predict(example),type(model.predict(example))\n",
    "le.inverse_transform(np.argmax(model.predict(example)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s3DkfrwyU4Dr"
   },
   "outputs": [],
   "source": [
    "# evaluate the model of test data\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(x_test)\n",
    "#print(classification_report(predictions,y_test))\n",
    "print(\"Accuracy :\",model.evaluate(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "hotel.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
